# =========================================
# ML MODELS FOR MENTAL WELLNESS DASHBOARD
# VERSION CORRIG√âE - 11 D√âC 2024
# =========================================

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error
from sentence_transformers import SentenceTransformer
import xgboost as xgb  # NOUVEAU: XGBoost au lieu de Linear Regression

import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

from scipy import stats
import base64
from io import BytesIO


class MentalHealthAnalyzer:
    def __init__(self):
        self.embedding_model = None
        self.scaler = StandardScaler()

        # Encoders pour les variables cat√©gorielles
        self.label_encoders = {}

        # Mod√®les ML distincts: K-Means, Random Forest, XGBoost
        self.random_forest = RandomForestClassifier(n_estimators=100, random_state=42)
        self.xgboost = xgb.XGBRegressor(n_estimators=100, random_state=42, max_depth=5)
        self.kmeans = KMeans(n_clusters=3, random_state=42)

        self.is_trained = False

    # -------------------------------------------------------------
    # INITIALISATION
    # -------------------------------------------------------------
    def initialize_models(self):
        """Charge le mod√®le d'embedding et initialise les mod√®les ML"""
        try:
            self.embedding_model = SentenceTransformer("all-MiniLM-L6-v2")
            print("‚úÖ Mod√®le d'embedding charg√©")
            print("‚úÖ Tous les mod√®les ML initialis√©s")
        except Exception as e:
            print("‚ùå ERREUR init ML:", e)
            raise

    # -------------------------------------------------------------
    # EMBEDDING DU TEXTE
    # -------------------------------------------------------------
    def generate_embedding(self, text):
        if self.embedding_model is None:
            self.initialize_models()
        return self.embedding_model.encode([text])[0]

    # -------------------------------------------------------------
    # VECTOR SEARCH CORRIG√â
    # -------------------------------------------------------------
    def find_similar_patients(self, query_embedding, mongo_patients, top_k=10):
        """
        CORRECTION: Prend maintenant 2 arguments comme attendu.
        mongo_patients = liste brute venant de MongoDB
        query_embedding = vecteur de la requ√™te utilisateur
        """

        enriched_patients = []

        for p in mongo_patients:
            desc = self.build_description(p)
            emb = self.embedding_model.encode([desc])[0]

            # Similarit√© cosinus
            sim = np.dot(query_embedding, emb) / (
                np.linalg.norm(query_embedding) * np.linalg.norm(emb) + 1e-10
            )

            enriched_patients.append(
                {
                    "patient_id": str(p.get("_id", "")),
                    "similarity_score": float(sim),
                    "name": p.get("Name", "Inconnu"),
                    "age": p.get("Age", None),
                    "risk_level": "Inconnu",
                    "raw": p,
                }
            )

        enriched_patients = sorted(
            enriched_patients, key=lambda x: x["similarity_score"], reverse=True
        )

        return enriched_patients[:top_k]

    # -------------------------------------------------------------
    # DESCRIPTION TEXTUELLE POUR EMBEDDING
    # -------------------------------------------------------------
    def build_description(self, p):
        """Construit un texte coh√©rent pour l'embedding"""
        desc = f"""
        Name: {p.get('Name')}
        Age: {p.get('Age')}
        Marital Status: {p.get('Marital Status')}
        Education Level: {p.get('Education Level')}
        Employment Status: {p.get('Employment Status')}
        Smoking: {p.get('Smoking Status')}
        Alcohol: {p.get('Alcohol Consumption')}
        Sleep: {p.get('Sleep Patterns')}
        Physical Activity: {p.get('Physical Activity Level')}
        Income: {p.get('Income')}
        History Mental Illness: {p.get('History of Mental Illness')}
        History Substance Abuse: {p.get('History of Substance Abuse')}
        Family Depression: {p.get('Family History of Depression')}
        Chronic Conditions: {p.get('Chronic Medical Conditions')}
        """
        return desc

    # -------------------------------------------------------------
    # EXTRACTION DES FEATURES NUM√âRIQUES
    # -------------------------------------------------------------
    def extract_features(self, p):
        """S√©lectionne les features utilis√©es par les mod√®les ML"""

        vector = []

        # Variables num√©riques
        vector.append(p.get("Age", 30))
        vector.append(p.get("Number of Children", 0))
        vector.append(p.get("Income", 50000) / 10000)

        # Variables cat√©gorielles
        categorical = [
            "Marital Status",
            "Education Level",
            "Employment Status",
            "Smoking Status",
            "Physical Activity Level",
            "Alcohol Consumption",
            "Dietary Habits",
            "Sleep Patterns",
            "History of Mental Illness",
            "History of Substance Abuse",
            "Family History of Depression",
            "Chronic Medical Conditions",
        ]

        for var in categorical:
            val = p.get(var, "Unknown")

            if var not in self.label_encoders:
                self.label_encoders[var] = LabelEncoder()
                # Fit avec toutes les valeurs possibles
                possible_values = ["Unknown", "Low", "Medium", "High", "Yes", "No", 
                                 "Single", "Married", "Divorced", "Widowed",
                                 "Employed", "Unemployed", "Student", "Retired",
                                 "High School", "Bachelor's Degree", "Master's Degree", "PhD",
                                 "Poor", "Fair", "Good", "Excellent",
                                 "Healthy", "Unhealthy", "Sedentary", "Moderate", "Active",
                                 "Non-smoker", "Former", "Current"]
                self.label_encoders[var].fit(possible_values)

            try:
                encoded = self.label_encoders[var].transform([val])[0]
            except:
                encoded = 0

            vector.append(encoded)

        return np.array(vector)

    # -------------------------------------------------------------
    # ENTRAINEMENT DES MOD√àLES SUR TES DONN√âES MONGO
    # -------------------------------------------------------------
    def train_models(self, mongo_patients):
        """
        Entra√Æne les 3 mod√®les ML distincts:
        1. Random Forest: Classification risque √©lev√©/faible
        2. R√©gression Lin√©aire: Pr√©diction score de bien-√™tre mental
        3. K-Means: Clustering des patients
        """
        print("üéØ Entra√Ænement des mod√®les ML...")

        X = []
        y_risk = []  # Pour Random Forest (classification binaire)
        y_wellness_score = []  # Pour r√©gression lin√©aire

        for p in mongo_patients:
            fv = self.extract_features(p)
            X.append(fv)

            # LABEL 1: Risque √©lev√© = combinaison de facteurs
            age = p.get("Age", 30)
            mental_illness = p.get("History of Mental Illness", "No")
            family_depression = p.get("Family History of Depression", "No")
            substance_abuse = p.get("History of Substance Abuse", "No")
            
            # Risque √©lev√© si: √¢ge > 45 OU historique maladie OU famille d√©pression
            high_risk = (age > 45) or (mental_illness == "Yes") or (family_depression == "Yes") or (substance_abuse == "Yes")
            y_risk.append(1 if high_risk else 0)

            # LABEL 2: Score de bien-√™tre mental (0-100)
            # Score bas√© sur plusieurs facteurs positifs/n√©gatifs
            score = 50  # Base

            # Facteurs positifs
            if p.get("Physical Activity Level") in ["Moderate", "Active"]:
                score += 10
            if p.get("Sleep Patterns") in ["Good", "Excellent"]:
                score += 15
            if p.get("Employment Status") == "Employed":
                score += 10
            if p.get("Dietary Habits") == "Healthy":
                score += 10

            # Facteurs n√©gatifs
            if p.get("Smoking Status") in ["Former", "Current"]:
                score -= 10
            if p.get("Alcohol Consumption") in ["High", "Medium"]:
                score -= 10
            if mental_illness == "Yes":
                score -= 20
            if substance_abuse == "Yes":
                score -= 15

            y_wellness_score.append(max(0, min(100, score)))

        X = np.array(X)
        y_risk = np.array(y_risk)
        y_wellness_score = np.array(y_wellness_score)

        # Feature scaling
        X_scaled = self.scaler.fit_transform(X)

        # Entra√Ænement des 3 mod√®les
        print("  Random Forest: classification risque...")
        self.random_forest.fit(X_scaled, y_risk)
        
        print("  XGBoost: pr√©diction score bien-√™tre...")
        self.xgboost.fit(X_scaled, y_wellness_score)
        
        print("  K-Means: clustering...")
        self.kmeans.fit(X_scaled)

        self.is_trained = True
        print("‚úÖ Mod√®les ML entra√Æn√©s avec succ√®s!")

    # -------------------------------------------------------------
    # APPLICATION DES MOD√àLES AUX PATIENTS SIMILAIRES
    # -------------------------------------------------------------
    def apply_ml_models(self, patients):
        results = []

        for p in patients:
            raw = p["raw"]

            fv = self.extract_features(raw)
            fv_scaled = self.scaler.transform([fv])

            # Pr√©dictions des 3 mod√®les
            pred_rf = int(self.random_forest.predict(fv_scaled)[0])
            pred_wellness = float(self.xgboost.predict(fv_scaled)[0])
            cluster = int(self.kmeans.predict(fv_scaled)[0])

            # Niveau de risque
            if pred_rf == 1:
                risk_level = "√âlev√©"
            else:
                risk_level = "Mod√©r√©"

            results.append(
                {
                    "patient_info": {
                        "id": p["patient_id"],
                        "name": p["name"],
                        "age": p["age"],
                        "similarity_score": p["similarity_score"],
                        "risk_level": risk_level,
                    },
                    "ml_predictions": {
                        "cluster_group": cluster,
                        "risk_category_rf": pred_rf,
                        "depression_probability": round(pred_wellness / 100, 3),
                        "wellness_score": round(pred_wellness, 1)
                    },
                }
            )

        return results

    # -------------------------------------------------------------
    # G√âN√âRATION DE 3 GRAPHES DISTINCTS
    # -------------------------------------------------------------
    def generate_cluster_plot(self, df, model_type="kmeans"):
        """
        G√©n√®re 3 types de graphes DISTINCTS selon le mod√®le:
        - kmeans: Scatter plot des clusters
        - random_forest: Feature importance
        - xgboost: Distribution des pr√©dictions
        """
        try:
            if model_type == "kmeans":
                return self._generate_kmeans_plot(df)
            elif model_type == "random_forest":
                return self._generate_rf_plot(df)
            elif model_type == "xgboost":
                return self._generate_xgboost_plot(df)
            else:
                return {"error": "Type de mod√®le inconnu"}

        except Exception as e:
            print(f"Erreur generate_cluster_plot: {e}")
            import traceback
            traceback.print_exc()
            return {"error": str(e)}

    def _generate_kmeans_plot(self, df):
        """Graphe 1: K-Means clustering"""
        cols = []
        for col in ["Age", "Income", "Number of Children"]:
            if col in df.columns:
                cols.append(col)

        if len(cols) < 2:
            return {"error": "Colonnes num√©riques insuffisantes"}

        data = df[cols].dropna().astype(float)
        if data.empty:
            return {"error": "Donn√©es vides"}

        X = self.scaler.fit_transform(data.values)
        
        kmeans = KMeans(n_clusters=3, random_state=42)
        labels = kmeans.fit_predict(X)

        plt.figure(figsize=(8, 6))
        
        scatter = plt.scatter(
            data[cols[0]],
            data[cols[1]],
            c=labels,
            cmap='viridis',
            s=60,
            alpha=0.7,
            edgecolor='black',
            linewidth=0.5
        )
        
        # Ajouter les centres des clusters
        centers = kmeans.cluster_centers_
        centers_original = self.scaler.inverse_transform(centers)
        plt.scatter(
            centers_original[:, 0],
            centers_original[:, 1],
            c='red',
            s=300,
            marker='*',
            edgecolor='black',
            linewidth=2,
            label='Centres des clusters'
        )

        plt.title("K-Means Clustering - Segmentation des Patients", fontsize=14, fontweight='bold')
        plt.xlabel(cols[0], fontsize=12)
        plt.ylabel(cols[1], fontsize=12)
        plt.colorbar(scatter, label='Cluster ID')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()

        buf = BytesIO()
        plt.savefig(buf, format="png", dpi=130, bbox_inches="tight")
        buf.seek(0)
        img_b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
        plt.close()

        return {
            "image": f"data:image/png;base64,{img_b64}",
            "model_type": "K-Means",
            "n_points": int(len(data)),
            "x_axis": cols[0],
            "y_axis": cols[1],
        }

    def _generate_rf_plot(self, df):
        """Graphe 2: Random Forest - Feature Importance"""
        if not self.is_trained:
            return {"error": "Mod√®les non entra√Æn√©s"}

        # Features utilis√©es (simplifi√© pour visualisation)
        feature_names = [
            "Age", "Nb Enfants", "Revenu",
            "Statut Marital", "√âducation", "Emploi",
            "Tabac", "Activit√©", "Alcool", "Alimentation",
            "Sommeil", "Maladie Mental", "Abus Substance",
            "Famille D√©pression", "Maladie Chronique"
        ]

        importances = self.random_forest.feature_importances_

        # Trier par importance
        indices = np.argsort(importances)[::-1][:10]  # Top 10

        plt.figure(figsize=(10, 6))
        plt.barh(
            range(len(indices)),
            importances[indices],
            color=plt.cm.viridis(np.linspace(0, 1, len(indices)))
        )
        plt.yticks(range(len(indices)), [feature_names[i] for i in indices])
        plt.xlabel("Importance", fontsize=12)
        plt.title("Random Forest - Importance des Variables", fontsize=14, fontweight='bold')
        plt.gca().invert_yaxis()
        plt.grid(axis='x', alpha=0.3)
        plt.tight_layout()

        buf = BytesIO()
        plt.savefig(buf, format="png", dpi=130, bbox_inches="tight")
        buf.seek(0)
        img_b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
        plt.close()

        return {
            "image": f"data:image/png;base64,{img_b64}",
            "model_type": "Random Forest",
            "n_points": len(importances),
            "x_axis": "Importance",
            "y_axis": "Features"
        }

    def _generate_xgboost_plot(self, df):
        """Graphe 3: XGBoost - Distribution des Scores"""
        if not self.is_trained:
            return {"error": "Mod√®les non entra√Æn√©s"}

        cols = []
        for col in ["Age", "Income", "Number of Children"]:
            if col in df.columns:
                cols.append(col)

        if len(cols) < 2:
            return {"error": "Colonnes num√©riques insuffisantes"}

        data = df[cols].dropna().astype(float)
        if data.empty:
            return {"error": "Donn√©es vides"}

        # Pr√©dire les scores de bien-√™tre pour tous les patients
        features = []
        for _, row in data.iterrows():
            mock_patient = {
                "Age": row.get("Age", 30),
                "Number of Children": row.get("Number of Children", 0),
                "Income": row.get("Income", 50000),
                "Marital Status": "Unknown",
                "Education Level": "Unknown",
                "Employment Status": "Unknown",
                "Smoking Status": "Unknown",
                "Physical Activity Level": "Unknown",
                "Alcohol Consumption": "Unknown",
                "Dietary Habits": "Unknown",
                "Sleep Patterns": "Unknown",
                "History of Mental Illness": "No",
                "History of Substance Abuse": "No",
                "Family History of Depression": "No",
                "Chronic Medical Conditions": "No"
            }
            fv = self.extract_features(mock_patient)
            features.append(fv)

        features = np.array(features)
        features_scaled = self.scaler.transform(features)
        wellness_scores = self.xgboost.predict(features_scaled)

        plt.figure(figsize=(10, 6))
        
        # Histogramme
        plt.hist(wellness_scores, bins=30, color='skyblue', edgecolor='black', alpha=0.7)
        plt.axvline(np.mean(wellness_scores), color='red', linestyle='--', linewidth=2, label=f'Moyenne: {np.mean(wellness_scores):.1f}')
        plt.axvline(np.median(wellness_scores), color='green', linestyle='--', linewidth=2, label=f'M√©diane: {np.median(wellness_scores):.1f}')
        
        plt.xlabel("Score de Bien-√™tre Mental (0-100)", fontsize=12)
        plt.ylabel("Nombre de Patients", fontsize=12)
        plt.title("XGBoost - Distribution des Scores de Bien-√™tre", fontsize=14, fontweight='bold')
        plt.legend()
        plt.grid(axis='y', alpha=0.3)
        plt.tight_layout()

        buf = BytesIO()
        plt.savefig(buf, format="png", dpi=130, bbox_inches="tight")
        buf.seek(0)
        img_b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
        plt.close()

        return {
            "image": f"data:image/png;base64,{img_b64}",
            "model_type": "XGBoost",
            "n_points": len(wellness_scores),
            "x_axis": "Score de Bien-√™tre",
            "y_axis": "Fr√©quence"
        }

    # -------------------------------------------------------------
    # EDF + CDF + PLOT
    # -------------------------------------------------------------
    def calculate_edf(self, data, variable):
        data = np.array(data)
        data = data[np.isfinite(data)]
        data.sort()

        n = len(data)
        edf = np.arange(1, n + 1) / n

        mu = np.mean(data)
        sigma = np.std(data)
        cdf = stats.norm.cdf(data, mu, sigma)

        # Plot EDF + CDF
        plt.figure(figsize=(8, 5))
        plt.step(data, edf, where="post", label="EDF", linewidth=2)
        plt.plot(data, cdf, label="CDF normale", linestyle="--", linewidth=2)
        plt.title(f"Fonction de Distribution Empirique - {variable}")
        plt.xlabel(variable)
        plt.ylabel("Probabilit√© cumulative")
        plt.legend()
        plt.grid(True, alpha=0.3)

        buffer = BytesIO()
        plt.savefig(buffer, format="png", dpi=120, bbox_inches="tight")
        buffer.seek(0)
        img = base64.b64encode(buffer.read()).decode()
        plt.close()

        return {
            "plot_image": "data:image/png;base64," + img,
            "statistics": {
                "mean": float(mu),
                "std": float(sigma),
                "min": float(np.min(data)),
                "max": float(np.max(data)),
            }
        }